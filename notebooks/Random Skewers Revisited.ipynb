{
 "metadata": {
  "name": "",
  "signature": "sha256:edab12d3914e33cb6405630f6ca4a548e4b507781815371bfb3c0458457ae201"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Considerando a decomposi\u00e7\u00e3o espectral das matrizes $A$ e $B$, com autovetores $u_i$ e $s_i$ formando bases ortonormais:\n",
      "\n",
      "$ A = \\sum_{i} \\lambda_i u_i u_i^{T} $ e $ B = \\sum_{i} \\gamma_i s_i s_i^{T} $ \n",
      "\n",
      "Pelo m\u00e9todo Random Skewers cria-se vetores aleat\u00f3rios unit\u00e1rios $\\beta$ e calcula-se a m\u00e9dia:\n",
      "\n",
      "$ < \\overline{A \\beta} \\cdot \\overline{B \\beta} > $\n",
      "\n",
      "Onde $ \\overline{A \\beta} $ \u00e9 igual ao valor $A \\beta$ normalizado ($ |A\\beta|= 1$). Este valor \u00e9 utilizado como uma m\u00e9trica de qu\u00e3o diferente s\u00e3o as matrizes $A$ e $B$ em rela\u00e7\u00e3o \u00e0 respostas para diferentes vetores de sele\u00e7\u00e3o.\n",
      "\n",
      "Utilizando que $A \\cdot B = A^TB$ e $ (AB)^T =  B^T A^T$:\n",
      "\n",
      "$ \\overline{A \\beta} \\cdot \\overline{B \\beta} = \\frac{1}{N_A N_B}(\\sum_{i} \\lambda_i u_i u_i^{T}\\beta)^T(\\sum_{j} \\gamma_j s_j s_j^{T}\\beta) $\n",
      "\n",
      "Onde $N_A$ e $N_B$ s\u00e3o os termos utilizados para a normaliza\u00e7\u00e3o, continuando:\n",
      "\n",
      "$\\frac{1}{N_A N_B} (\\sum_{i} \\beta^T\\lambda_i u_i u_i^{T})(\\sum_{j} \\gamma_j s_j s_j^{T}\\beta) = \\frac{1}{N_A N_B} (\\sum_{i,j} \\lambda_i \\gamma_j \\beta^T u_i u_i^{T} s_j s_j^{T}\\beta) $ \n",
      "\n",
      "Com $u_i^Ts_j = u_i \\cdot s_j = cos\\theta_{ij}$\n",
      "\n",
      "$ \\beta^T u_i = u_i \\cdot \\beta = cos\\theta_i^{A}$\n",
      "\n",
      "$ s_j^T \\beta = s_j \\cdot \\beta = cos\\theta_j^{B}$\n",
      "\n",
      "Teremos\n",
      "\n",
      "$ \\frac{1}{N_A N_B} (\\sum_{i,j} \\lambda_i \\gamma_j cos\\theta_{ij} cos\\theta_i^{A} cos\\theta_j^{B}) $ \n",
      "\n",
      "Para acharmos $N_A$ e $N_B$ basta considera a express\u00e3o:\n",
      "\n",
      "$  A \\beta \\cdot A \\beta  = |A\\beta|^2$  \n",
      "\n",
      "$ A \\beta \\cdot A \\beta = \\sum_{i,j} \\lambda_i \\lambda_j cos\\theta_{ij} cos\\theta_i^{A} cos\\theta_j^{A} $\n",
      "\n",
      "E como $cos\\theta_{ij} = 0$ para $i \\neq j$ e $1$ caso contr\u00e1rio\n",
      "\n",
      "$ A \\beta \\cdot A \\beta = \\sum_{i} \\lambda_i^2 cos^2\\theta_i^{A} $\n",
      "\n",
      "Logo\n",
      "\n",
      "$N_A = \\frac{1}{\\sqrt{\\sum_{i} \\lambda_i^2 cos^2\\theta_i^{A}}} $\n",
      "\n",
      "e equivalentemente:\n",
      "\n",
      "$N_B = \\frac{1}{\\sqrt{\\sum_{i} \\gamma_i^2 cos^2\\theta_i^{B}}} $\n",
      "\n",
      "$ RS(A,B) = \\langle \\frac{\\sum_{i,j} \\lambda_i \\gamma_j cos\\theta_{ij} cos\\theta_i^{A} cos\\theta_j^{B}}{\\sqrt{\\sum_{ij} \\lambda_i^2\\gamma_j^2 cos^2\\theta_i^{A}cos^2\\theta_j^{B}} } \\rangle$ \n",
      "\n",
      "Agora precisamos apenas integrar o \u00faltimo termo. De qualquer forma nota-se que o\n",
      "\n",
      "$ RS(A,B) \\leq \\sum_{ij}\\frac{ \\lambda_i\\gamma_j cos\\theta_{ij}}{\\sum{ij}\\lambda_i\\gamma_j} $\n",
      "\n",
      "Onde o \u00faltimo termo nada mais \u00e9 do que o PCA similarity factor, a medida de Krzanowski com os pesos dados pelos autovalores.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}